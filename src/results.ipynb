{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_results = []\n",
    "\n",
    "with open(\"test_responses.jsonl\",'r') as f : \n",
    "    for line in f: \n",
    "        if line.strip():\n",
    "            data = json.loads(line)\n",
    "            test_model_results.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>test_model</th>\n",
       "      <th>Encountered_Problems</th>\n",
       "      <th>test_model_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>openai:gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>Based on the information provided in the conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>True</td>\n",
       "      <td>[Errno 61] Connection refused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>openai:gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>1. Wüsthof - 14 degrees\\n2. MAC - 15 degrees\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>True</td>\n",
       "      <td>[Errno 61] Connection refused</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id            test_model  Encountered_Problems  \\\n",
       "0          0  openai:gpt-3.5-turbo                 False   \n",
       "1          0       ollama:llama3.2                  True   \n",
       "2          1  openai:gpt-3.5-turbo                 False   \n",
       "3          1       ollama:llama3.2                  True   \n",
       "\n",
       "                                 test_model_response  \n",
       "0  Based on the information provided in the conte...  \n",
       "1                      [Errno 61] Connection refused  \n",
       "2  1. Wüsthof - 14 degrees\\n2. MAC - 15 degrees\\n...  \n",
       "3                      [Errno 61] Connection refused  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_model = pd.DataFrame(test_model_results)\n",
    "df_test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided in the context document, your risk factors for dementia include high blood pressure, diabetes, obesity, lack of physical activity, poor diet, high alcohol consumption, low cognitive engagement, depression, traumatic brain injury, hearing loss, and social isolation.\n",
      "\n",
      "Cognitive engagement is important in reducing the risk of dementia because it is thought to support the development of a \"cognitive reserve.\" This means that actively using your brain throughout your life may provide protection against brain cell damage caused by dementia. Therefore, engaging in activities that challenge and stimulate your brain can help reduce the risk of developing dementia.\n"
     ]
    }
   ],
   "source": [
    "print(df_test_model['test_model_response'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 61] Connection refused\n"
     ]
    }
   ],
   "source": [
    "print(df_test_model['test_model_response'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "judges_result = []\n",
    "\n",
    "with open(\"judge_responses.jsonl\",'r') as f : \n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            content = json.loads(line)\n",
    "            judges_result.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judged_model</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>judge_model</th>\n",
       "      <th>Encountered_Problems</th>\n",
       "      <th>judge_model_response</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai:gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>anthropic:claude-3-7-sonnet-20250219</td>\n",
       "      <td>False</td>\n",
       "      <td>Sentence 1: Based on the information provided ...</td>\n",
       "      <td>Inaccurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai:gpt-3.5-turbo</td>\n",
       "      <td>0</td>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>True</td>\n",
       "      <td>[Errno 61] Connection refused</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>anthropic:claude-3-7-sonnet-20250219</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai:gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>anthropic:claude-3-7-sonnet-20250219</td>\n",
       "      <td>False</td>\n",
       "      <td>Sentence 1: Wüsthof - 14 degrees\\nSentence 1 l...</td>\n",
       "      <td>Inaccurate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai:gpt-3.5-turbo</td>\n",
       "      <td>1</td>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>True</td>\n",
       "      <td>[Errno 61] Connection refused</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>anthropic:claude-3-7-sonnet-20250219</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>ollama:llama3.2</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           judged_model  sample_id                           judge_model  \\\n",
       "0  openai:gpt-3.5-turbo          0  anthropic:claude-3-7-sonnet-20250219   \n",
       "1  openai:gpt-3.5-turbo          0                       ollama:llama3.2   \n",
       "2       ollama:llama3.2          0  anthropic:claude-3-7-sonnet-20250219   \n",
       "3       ollama:llama3.2          0                       ollama:llama3.2   \n",
       "4  openai:gpt-3.5-turbo          1  anthropic:claude-3-7-sonnet-20250219   \n",
       "5  openai:gpt-3.5-turbo          1                       ollama:llama3.2   \n",
       "6       ollama:llama3.2          1  anthropic:claude-3-7-sonnet-20250219   \n",
       "7       ollama:llama3.2          1                       ollama:llama3.2   \n",
       "\n",
       "  Encountered_Problems                               judge_model_response  \\\n",
       "0                False  Sentence 1: Based on the information provided ...   \n",
       "1                 True                      [Errno 61] Connection refused   \n",
       "2       Not applicable                                     Not applicable   \n",
       "3       Not applicable                                     Not applicable   \n",
       "4                False  Sentence 1: Wüsthof - 14 degrees\\nSentence 1 l...   \n",
       "5                 True                      [Errno 61] Connection refused   \n",
       "6       Not applicable                                     Not applicable   \n",
       "7       Not applicable                                     Not applicable   \n",
       "\n",
       "          verdict  \n",
       "0      Inaccurate  \n",
       "1            None  \n",
       "2  Not applicable  \n",
       "3  Not applicable  \n",
       "4      Inaccurate  \n",
       "5            None  \n",
       "6  Not applicable  \n",
       "7  Not applicable  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_judges = pd.DataFrame(judges_result)\n",
    "df_judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(df_test_model))\n",
    "print(len(df_judges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore some samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Based on the information provided in the context document, your risk factors for dementia include high blood pressure, diabetes, obesity, lack of physical activity, poor diet, high alcohol consumption, low cognitive engagement, depression, traumatic brain injury, hearing loss, and social isolation.\n",
      "Sentence 1 label: Inaccurate\n",
      "\n",
      "Sentence 2: Cognitive engagement is important because it is thought to support the development of a \"cognitive reserve,\" which may protect against brain cell damage caused by dementia.\n",
      "Sentence 2 label: Accurate\n",
      "\n",
      "Sentence 3: Engaging in activities that challenge and stimulate the brain throughout life may help reduce the risk of developing dementia.\n",
      "Sentence 3 label: Accurate\n",
      "\n",
      "Final Answer: Inaccurate\n",
      "\n",
      "The first sentence is inaccurate because it lists all possible risk factors from the evidence as applying to the person in the query, when in fact the query only mentions some of these factors. The person states they \"never smoked\" (so smoking is not a risk factor for them), had their \"ears blown out in the war\" (indicating hearing loss), get \"a case of the sads pretty regular\" (suggesting depression), and \"eat mostly garbage\" (indicating poor diet). The response incorrectly assumes the person has high blood pressure, diabetes, obesity, lack of physical activity, high alcohol consumption, and social isolation, which were not mentioned in the query.\n"
     ]
    }
   ],
   "source": [
    "print(df_judges['judge model response'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentence\": \"I'm middle-aged, never smoked, had my ears blown out in the war, get a case of the sads pretty regular, and eat mostly garbage.\", \"label\": \"no_rad\", \"rationale\": \"This is a personal statement and does not require factual attribution.\", \"excerpt\": null}\n",
      "{\"sentence\": \"What are my risk factors for dementia?\", \"label\": \"unsupported\", \"rationale\": \"The question is asking for specific information, but the context only provides general information about risk factors for dementia.\", \"excerpt\": null}\n",
      "{\"sentence\": \"What does cognitive engagement have to do with it?\", \"label\": \"no_rad\", \"rationale\": \"This is a follow-up question and does not require factual attribution.\", \"excerpt\": null}\n",
      "{\"sentence\": \"Based on the information provided in the context document, your risk factors for dementia include high blood pressure, diabetes, obesity, lack of physical activity, poor diet, high alcohol consumption, low cognitive engagement, depression, traumatic brain injury, hearing loss, and social isolation.\", \"label\": \"supported\", \"rationale\": \"The sentence is a summary of the context and lists specific risk factors for dementia.\", \"excerpt\": null}\n",
      "{\"sentence\": \"Cognitive engagement is important because it is thought to support the development of a \\\"cognitive reserve,\\\" which may protect against brain cell damage caused by dementia. Engaging in activities that challenge and stimulate the brain throughout life may help reduce the risk of developing dementia.\", \"label\": \"supported\", \"rationale\": \"The sentence is supported by the context, which mentions cognitive engagement as a protective factor against dementia.\", \"excerpt\": null}\n"
     ]
    }
   ],
   "source": [
    "print(df_judges['judge model response'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_MODEL = 'openai:gpt-3.5-turbo' # feel free to checkout accuracy for other models \n",
    "# TEST_MODEL = 'openai:gpt-4o' # feel free to checkout accuracy for other models \n",
    "TEST_MODEL = 'ollama:llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>verdict</th>\n",
       "      <th>Inaccurate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judge model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:llama3.2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "verdict                               Inaccurate\n",
       "judge model                                     \n",
       "anthropic:claude-3-7-sonnet-20250219           2\n",
       "ollama:llama3.2                                2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_judges[df_judges['judged_model']==TEST_MODEL].groupby('judge model')['verdict'].value_counts().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Accurate'], dtype='object', name='verdict')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m counts \u001b[38;5;241m=\u001b[39m df_filtered\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudge model\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverdict\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      3\u001b[0m percentages \u001b[38;5;241m=\u001b[39m counts \u001b[38;5;241m/\u001b[39m counts\u001b[38;5;241m.\u001b[39mgroupby(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpercentages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAccurate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m result\n",
      "File \u001b[0;32m~/Desktop/Galaxy/MyLabV2/Facts-Grounding-with-Langchain/langvenv/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Galaxy/MyLabV2/Facts-Grounding-with-Langchain/langvenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Galaxy/MyLabV2/Facts-Grounding-with-Langchain/langvenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Accurate'], dtype='object', name='verdict')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df_filtered = df_judges[df_judges['judged_model'] == TEST_MODEL]\n",
    "counts = df_filtered.groupby('judge model')['verdict'].value_counts()\n",
    "percentages = counts / counts.groupby(level=0).sum() * 100\n",
    "result = percentages.unstack(fill_value=0)[[\"Accurate\"]]\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
